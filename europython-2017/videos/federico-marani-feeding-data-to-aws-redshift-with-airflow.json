{
  "description": "Airflow is a powerful system to schedule workflows and define them as\na collection of interdependent scripts. It is the perfect companion\nto do extract/transform/load pipelines into data warehouses, such as\nRedshift.\n\nThis talk will introduce some of the basis of Airflow and some of the\nconcepts that are data pipeline specific, like backfills, retries,\netc. Then there will be some examples on how to integrate this, along\nwith some lessons learned there.\n\nAt the end, there will be a part dedicated to Redshift, how to\nstructure data there, how to do some basic transformation\npre-loading, how to manage the schema using SQLAlchemy and Alembic.",
  "duration": 2368,
  "recorded": "2017-07-13",
  "speakers": [
    "Federico Marani"
  ],
  "thumbnail_url": "https://i.ytimg.com/vi/0s6lmVbvoFo/hqdefault.jpg",
  "title": "Feeding data to AWS Redshift with Airflow",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=0s6lmVbvoFo"
    }
  ]
}
